{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m752k2fWKDql"
      },
      "source": [
        "# How to use Weave with PII data:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C70egOGRLCgm"
      },
      "source": [
        "In this tutorial, we'll demonstrate how to utilize Weave while preventing your Personally Identifiable Information (PII) data from being incorporated into Weave or the LLMs you employ.\n",
        "\n",
        "To protect our PII data, we'll employ Microsoft's [Presidio](https://microsoft.github.io/presidio/), a Python-based data protection SDK. This tool provides redaction and replacement functionalities, both of which we will implement in this tutorial.\n",
        "\n",
        "For this use-case. We will leverage Anthropic's claude-3-sonnet to perform sentiment analysis. While we use Weave's [Traces](https://wandb.github.io/weave/quickstart) to track and analize the LLM's API calls. Sonnet will receive block of text and output one of the following sentiment classification:\n",
        "1. positive\n",
        "2. negative\n",
        "3. neutral"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "qi-VNJT35v2j",
        "outputId": "8870f124-e141-4fee-8789-024d81944c56"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting presidio_analyzer\n",
            "  Downloading presidio_analyzer-2.2.355-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting phonenumbers<9.0.0,>=8.12 (from presidio_analyzer)\n",
            "  Downloading phonenumbers-8.13.43-py2.py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from presidio_analyzer) (6.0.2)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from presidio_analyzer) (2024.5.15)\n",
            "Requirement already satisfied: spacy<4.0.0,>=3.4.4 in /usr/local/lib/python3.10/dist-packages (from presidio_analyzer) (3.7.5)\n",
            "Collecting tldextract (from presidio_analyzer)\n",
            "  Downloading tldextract-5.1.2-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<4.0.0,>=3.4.4->presidio_analyzer) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4.0.0,>=3.4.4->presidio_analyzer) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4.0.0,>=3.4.4->presidio_analyzer) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<4.0.0,>=3.4.4->presidio_analyzer) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<4.0.0,>=3.4.4->presidio_analyzer) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy<4.0.0,>=3.4.4->presidio_analyzer) (8.2.5)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<4.0.0,>=3.4.4->presidio_analyzer) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<4.0.0,>=3.4.4->presidio_analyzer) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<4.0.0,>=3.4.4->presidio_analyzer) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4.0.0,>=3.4.4->presidio_analyzer) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4.0.0,>=3.4.4->presidio_analyzer) (0.12.3)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4.0.0,>=3.4.4->presidio_analyzer) (4.66.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4.0.0,>=3.4.4->presidio_analyzer) (2.32.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<4.0.0,>=3.4.4->presidio_analyzer) (2.8.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<4.0.0,>=3.4.4->presidio_analyzer) (3.1.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<4.0.0,>=3.4.4->presidio_analyzer) (71.0.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4.0.0,>=3.4.4->presidio_analyzer) (24.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4.0.0,>=3.4.4->presidio_analyzer) (3.4.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4.0.0,>=3.4.4->presidio_analyzer) (1.26.4)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from tldextract->presidio_analyzer) (3.7)\n",
            "Collecting requests-file>=1.4 (from tldextract->presidio_analyzer)\n",
            "  Downloading requests_file-2.1.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: filelock>=3.0.8 in /usr/local/lib/python3.10/dist-packages (from tldextract->presidio_analyzer) (3.15.4)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy<4.0.0,>=3.4.4->presidio_analyzer) (1.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<4.0.0,>=3.4.4->presidio_analyzer) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<4.0.0,>=3.4.4->presidio_analyzer) (2.20.1)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<4.0.0,>=3.4.4->presidio_analyzer) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<4.0.0,>=3.4.4->presidio_analyzer) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<4.0.0,>=3.4.4->presidio_analyzer) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<4.0.0,>=3.4.4->presidio_analyzer) (2024.7.4)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<4.0.0,>=3.4.4->presidio_analyzer) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<4.0.0,>=3.4.4->presidio_analyzer) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<4.0.0,>=3.4.4->presidio_analyzer) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<4.0.0,>=3.4.4->presidio_analyzer) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<4.0.0,>=3.4.4->presidio_analyzer) (13.7.1)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<4.0.0,>=3.4.4->presidio_analyzer) (0.18.1)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<4.0.0,>=3.4.4->presidio_analyzer) (7.0.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<4.0.0,>=3.4.4->presidio_analyzer) (2.1.5)\n",
            "Requirement already satisfied: marisa-trie>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<4.0.0,>=3.4.4->presidio_analyzer) (1.2.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<4.0.0,>=3.4.4->presidio_analyzer) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<4.0.0,>=3.4.4->presidio_analyzer) (2.16.1)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy<4.0.0,>=3.4.4->presidio_analyzer) (1.16.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<4.0.0,>=3.4.4->presidio_analyzer) (0.1.2)\n",
            "Downloading presidio_analyzer-2.2.355-py3-none-any.whl (109 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m109.2/109.2 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading phonenumbers-8.13.43-py2.py3-none-any.whl (2.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m59.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tldextract-5.1.2-py3-none-any.whl (97 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.6/97.6 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading requests_file-2.1.0-py2.py3-none-any.whl (4.2 kB)\n",
            "Installing collected packages: phonenumbers, requests-file, tldextract, presidio_analyzer\n",
            "Successfully installed phonenumbers-8.13.43 presidio_analyzer-2.2.355 requests-file-2.1.0 tldextract-5.1.2\n",
            "Collecting presidio_anonymizer\n",
            "  Downloading presidio_anonymizer-2.2.355-py3-none-any.whl.metadata (8.2 kB)\n",
            "Collecting azure-core (from presidio_anonymizer)\n",
            "  Downloading azure_core-1.30.2-py3-none-any.whl.metadata (37 kB)\n",
            "Collecting pycryptodome>=3.10.1 (from presidio_anonymizer)\n",
            "  Downloading pycryptodome-3.20.0-cp35-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.4 kB)\n",
            "Requirement already satisfied: requests>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from azure-core->presidio_anonymizer) (2.32.3)\n",
            "Requirement already satisfied: six>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from azure-core->presidio_anonymizer) (1.16.0)\n",
            "Requirement already satisfied: typing-extensions>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from azure-core->presidio_anonymizer) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.21.0->azure-core->presidio_anonymizer) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.21.0->azure-core->presidio_anonymizer) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.21.0->azure-core->presidio_anonymizer) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.21.0->azure-core->presidio_anonymizer) (2024.7.4)\n",
            "Downloading presidio_anonymizer-2.2.355-py3-none-any.whl (31 kB)\n",
            "Downloading pycryptodome-3.20.0-cp35-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m66.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading azure_core-1.30.2-py3-none-any.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.3/194.3 kB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pycryptodome, azure-core, presidio_anonymizer\n",
            "Successfully installed azure-core-1.30.2 presidio_anonymizer-2.2.355 pycryptodome-3.20.0\n",
            "Collecting en-core-web-lg==3.7.1\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-3.7.1/en_core_web_lg-3.7.1-py3-none-any.whl (587.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m587.7/587.7 MB\u001b[0m \u001b[31m882.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.2 in /usr/local/lib/python3.10/dist-packages (from en-core-web-lg==3.7.1) (3.7.5)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (8.2.5)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (0.12.3)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (4.66.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2.32.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2.8.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (3.1.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (71.0.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (24.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (3.4.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (1.26.4)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (1.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2.20.1)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2024.7.4)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (13.7.1)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (0.18.1)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (7.0.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2.1.5)\n",
            "Requirement already satisfied: marisa-trie>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (1.2.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2.16.1)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (1.16.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (0.1.2)\n",
            "Installing collected packages: en-core-web-lg\n",
            "Successfully installed en-core-web-lg-3.7.1\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_lg')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n",
            "Collecting Faker\n",
            "  Downloading Faker-27.0.0-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.4 in /usr/local/lib/python3.10/dist-packages (from Faker) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.4->Faker) (1.16.0)\n",
            "Downloading Faker-27.0.0-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m44.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: Faker\n",
            "Successfully installed Faker-27.0.0\n",
            "Collecting weave\n",
            "  Downloading weave-0.50.14-py3-none-any.whl.metadata (8.8 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from weave) (4.12.2)\n",
            "Requirement already satisfied: pyarrow<17.0.0,>=14.0.1 in /usr/local/lib/python3.10/dist-packages (from weave) (14.0.2)\n",
            "Collecting openai>=1.0.0 (from weave)\n",
            "  Downloading openai-1.40.7-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting tiktoken>=0.4.0 (from weave)\n",
            "  Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: pydantic>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from weave) (2.8.2)\n",
            "Requirement already satisfied: rich>=13.7.0 in /usr/local/lib/python3.10/dist-packages (from weave) (13.7.1)\n",
            "Requirement already satisfied: aiohttp>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from weave) (3.10.2)\n",
            "Collecting aiofiles>=22.1.0 (from weave)\n",
            "  Downloading aiofiles-24.1.0-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting aioprocessing>=2.0.1 (from weave)\n",
            "  Downloading aioprocessing-2.0.1-py3-none-any.whl.metadata (7.6 kB)\n",
            "Requirement already satisfied: Werkzeug>=3.0.3 in /usr/local/lib/python3.10/dist-packages (from weave) (3.0.3)\n",
            "Collecting janus>=1.0.0 (from weave)\n",
            "  Downloading janus-1.0.0-py3-none-any.whl.metadata (4.5 kB)\n",
            "Collecting python-json-logger>=2.0.4 (from weave)\n",
            "  Downloading python_json_logger-2.0.7-py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: numpy>=1.21 in /usr/local/lib/python3.10/dist-packages (from weave) (1.26.4)\n",
            "Collecting wandb>=0.16.4 (from weave)\n",
            "  Downloading wandb-0.17.6-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
            "Collecting graphql-core>3 (from weave)\n",
            "  Downloading graphql_core-3.2.3-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting gql>=3.4.1 (from gql[requests]>=3.4.1->weave)\n",
            "  Downloading gql-3.5.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Collecting analytics-python>=1.2.9 (from weave)\n",
            "  Downloading analytics_python-1.4.post1-py2.py3-none-any.whl.metadata (2.0 kB)\n",
            "Requirement already satisfied: packaging>=21.0 in /usr/local/lib/python3.10/dist-packages (from weave) (24.1)\n",
            "Requirement already satisfied: tenacity!=8.4.0,>=8.3.0 in /usr/local/lib/python3.10/dist-packages (from weave) (9.0.0)\n",
            "Collecting emoji>=2.12.1 (from weave)\n",
            "  Downloading emoji-2.12.1-py3-none-any.whl.metadata (5.4 kB)\n",
            "Collecting uuid-utils>=0.9.0 (from weave)\n",
            "  Downloading uuid_utils-0.9.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.6 kB)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.8.3->weave) (2.3.5)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.8.3->weave) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.8.3->weave) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.8.3->weave) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.8.3->weave) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.8.3->weave) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.8.3->weave) (4.0.3)\n",
            "Requirement already satisfied: requests<3.0,>=2.7 in /usr/local/lib/python3.10/dist-packages (from analytics-python>=1.2.9->weave) (2.32.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from analytics-python>=1.2.9->weave) (1.16.0)\n",
            "Collecting monotonic>=1.5 (from analytics-python>=1.2.9->weave)\n",
            "  Downloading monotonic-1.6-py2.py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting backoff==1.10.0 (from analytics-python>=1.2.9->weave)\n",
            "  Downloading backoff-1.10.0-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: python-dateutil>2.1 in /usr/local/lib/python3.10/dist-packages (from analytics-python>=1.2.9->weave) (2.8.2)\n",
            "INFO: pip is looking at multiple versions of gql to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting gql>=3.4.1 (from gql[requests]>=3.4.1->weave)\n",
            "  Downloading gql-3.4.1-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Collecting analytics-python>=1.2.9 (from weave)\n",
            "  Downloading analytics_python-1.4.0-py2.py3-none-any.whl.metadata (1.8 kB)\n",
            "  Downloading analytics_python-1.3.1-py2.py3-none-any.whl.metadata (1.8 kB)\n",
            "  Downloading analytics_python-1.2.9-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting backoff<3.0,>=1.11.1 (from gql>=3.4.1->gql[requests]>=3.4.1->weave)\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.0 in /usr/local/lib/python3.10/dist-packages (from gql>=3.4.1->gql[requests]>=3.4.1->weave) (3.7.1)\n",
            "Collecting requests-toolbelt<2,>=1.0.0 (from gql[requests]>=3.4.1->weave)\n",
            "  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai>=1.0.0->weave) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai>=1.0.0->weave)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl.metadata (7.2 kB)\n",
            "Collecting jiter<1,>=0.4.0 (from openai>=1.0.0->weave)\n",
            "  Downloading jiter-0.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai>=1.0.0->weave) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai>=1.0.0->weave) (4.66.5)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0.0->weave) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0.0->weave) (2.20.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=13.7.0->weave) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=13.7.0->weave) (2.16.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken>=0.4.0->weave) (2024.5.15)\n",
            "Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb>=0.16.4->weave) (8.1.7)\n",
            "Collecting docker-pycreds>=0.4.0 (from wandb>=0.16.4->weave)\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting gitpython!=3.1.29,>=1.0.0 (from wandb>=0.16.4->weave)\n",
            "  Downloading GitPython-3.1.43-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.10/dist-packages (from wandb>=0.16.4->weave) (4.2.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,<6,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb>=0.16.4->weave) (3.20.3)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb>=0.16.4->weave) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from wandb>=0.16.4->weave) (6.0.2)\n",
            "Collecting sentry-sdk>=1.0.0 (from wandb>=0.16.4->weave)\n",
            "  Downloading sentry_sdk-2.13.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Collecting setproctitle (from wandb>=0.16.4->weave)\n",
            "  Downloading setproctitle-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.9 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb>=0.16.4->weave) (71.0.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from Werkzeug>=3.0.3->weave) (2.1.5)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.0->gql>=3.4.1->gql[requests]>=3.4.1->weave) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.0->gql>=3.4.1->gql[requests]>=3.4.1->weave) (1.2.2)\n",
            "Collecting gitdb<5,>=4.0.1 (from gitpython!=3.1.29,>=1.0.0->wandb>=0.16.4->weave)\n",
            "  Downloading gitdb-4.0.11-py3-none-any.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai>=1.0.0->weave) (2024.7.4)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai>=1.0.0->weave)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai>=1.0.0->weave)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=13.7.0->weave) (0.1.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.7->analytics-python>=1.2.9->weave) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.7->analytics-python>=1.2.9->weave) (2.0.7)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb>=0.16.4->weave)\n",
            "  Downloading smmap-5.0.1-py3-none-any.whl.metadata (4.3 kB)\n",
            "Downloading weave-0.50.14-py3-none-any.whl (30.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.2/30.2 MB\u001b[0m \u001b[31m20.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiofiles-24.1.0-py3-none-any.whl (15 kB)\n",
            "Downloading aioprocessing-2.0.1-py3-none-any.whl (14 kB)\n",
            "Downloading analytics_python-1.2.9-py2.py3-none-any.whl (13 kB)\n",
            "Downloading gql-3.5.0-py2.py3-none-any.whl (74 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.0/74.0 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading emoji-2.12.1-py3-none-any.whl (431 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m431.4/431.4 kB\u001b[0m \u001b[31m23.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading graphql_core-3.2.3-py3-none-any.whl (202 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m202.9/202.9 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading janus-1.0.0-py3-none-any.whl (6.9 kB)\n",
            "Downloading openai-1.40.7-py3-none-any.whl (361 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m361.2/361.2 kB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_json_logger-2.0.7-py3-none-any.whl (8.1 kB)\n",
            "Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m25.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading uuid_utils-0.9.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (310 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m310.7/310.7 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading wandb-0.17.6-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.1/7.1 MB\u001b[0m \u001b[31m41.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Downloading GitPython-3.1.43-py3-none-any.whl (207 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jiter-0.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (318 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.9/318.9 kB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sentry_sdk-2.13.0-py2.py3-none-any.whl (309 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m309.1/309.1 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading setproctitle-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
            "Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
            "Installing collected packages: uuid-utils, smmap, setproctitle, sentry-sdk, python-json-logger, jiter, janus, h11, graphql-core, emoji, docker-pycreds, backoff, aioprocessing, aiofiles, tiktoken, requests-toolbelt, httpcore, gql, gitdb, analytics-python, httpx, gitpython, wandb, openai, weave\n",
            "Successfully installed aiofiles-24.1.0 aioprocessing-2.0.1 analytics-python-1.2.9 backoff-2.2.1 docker-pycreds-0.4.0 emoji-2.12.1 gitdb-4.0.11 gitpython-3.1.43 gql-3.5.0 graphql-core-3.2.3 h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 janus-1.0.0 jiter-0.5.0 openai-1.40.7 python-json-logger-2.0.7 requests-toolbelt-1.0.0 sentry-sdk-2.13.0 setproctitle-1.3.3 smmap-5.0.1 tiktoken-0.7.0 uuid-utils-0.9.0 wandb-0.17.6 weave-0.50.14\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.5/62.5 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting anthropic\n",
            "  Downloading anthropic-0.34.0-py3-none-any.whl.metadata (18 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from anthropic) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from anthropic) (1.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from anthropic) (0.27.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from anthropic) (0.5.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from anthropic) (2.8.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from anthropic) (1.3.1)\n",
            "Requirement already satisfied: tokenizers>=0.13.0 in /usr/local/lib/python3.10/dist-packages (from anthropic) (0.19.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from anthropic) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->anthropic) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->anthropic) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->anthropic) (2024.7.4)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->anthropic) (1.0.5)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->anthropic) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->anthropic) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->anthropic) (2.20.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from tokenizers>=0.13.0->anthropic) (0.23.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic) (3.15.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic) (2024.6.1)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic) (4.66.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic) (2.0.7)\n",
            "Downloading anthropic-0.34.0-py3-none-any.whl (891 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m891.5/891.5 kB\u001b[0m \u001b[31m35.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: anthropic\n",
            "Successfully installed anthropic-0.34.0\n"
          ]
        }
      ],
      "source": [
        "# @title required python packages:\n",
        "!pip install presidio_analyzer\n",
        "!pip install presidio_anonymizer\n",
        "!python -m spacy download en_core_web_lg # Presidio uses spacy NLP engine\n",
        "!pip install Faker                       # we'll use Faker to replace PII data with fake data\n",
        "!pip install weave                        # To leverage Traces\n",
        "!pip install set-env-colab-kaggle-dotenv -q # for env var\n",
        "!pip install anthropic                      # to use sonnet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sYEX_yPqMDOk"
      },
      "source": [
        "# Method 1A:\n",
        "Our first method involves complete removal of PII data using Presidio. This approach redacts PII and replaces it with a placeholder representing the PII type. For example:\n",
        "```\n",
        " \"My name is Alex\"\n",
        "```\n",
        "\n",
        "Will be:\n",
        "\n",
        "```\n",
        " \"My name is <PERSON>\"\n",
        "```\n",
        "Presidio comes with a built-in [list of recognizable entities](https://microsoft.github.io/presidio/supported_entities/). We can select the ones that are important for our use case. In the below example, we are only looking at redicating names and phone numbers from our text:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bh6MgL3g6sc2"
      },
      "outputs": [],
      "source": [
        "from presidio_analyzer import AnalyzerEngine\n",
        "from presidio_anonymizer import AnonymizerEngine\n",
        "\n",
        "text= \"My phone number is 212-555-5555 and my name is alex\"\n",
        "\n",
        "# Set up the engine, loads the NLP module (spaCy model by default)\n",
        "# and other PII recognizers\n",
        "analyzer = AnalyzerEngine()\n",
        "\n",
        "# Call analyzer to get results\n",
        "results = analyzer.analyze(text=text,\n",
        "                           entities=[\"PHONE_NUMBER\", \"PERSON\"],\n",
        "                           language='en')\n",
        "\n",
        "# Analyzer results are passed to the AnonymizerEngine for anonymization\n",
        "\n",
        "anonymizer = AnonymizerEngine()\n",
        "\n",
        "anonymized_text = anonymizer.anonymize(text=text,analyzer_results=results)\n",
        "\n",
        "print(anonymized_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zq1abYAUl4rV"
      },
      "source": [
        "Let's encapsulate the previous step into a function and expand the entity recognition capabilities. We will expand our redaction scope to include addresses, email addresses, and US Social Security numbers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "rQyUmN5nmQrj",
        "outputId": "4a538fda-c079-4cea-a65f-ccbeee58f17e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - CreditCardRecognizer supported languages: es, registry supported languages: en\n",
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - CreditCardRecognizer supported languages: it, registry supported languages: en\n",
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - CreditCardRecognizer supported languages: pl, registry supported languages: en\n",
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - EsNifRecognizer supported languages: es, registry supported languages: en\n",
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - EsNieRecognizer supported languages: es, registry supported languages: en\n",
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - ItDriverLicenseRecognizer supported languages: it, registry supported languages: en\n",
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - ItFiscalCodeRecognizer supported languages: it, registry supported languages: en\n",
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - ItVatCodeRecognizer supported languages: it, registry supported languages: en\n",
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - ItIdentityCardRecognizer supported languages: it, registry supported languages: en\n",
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - ItPassportRecognizer supported languages: it, registry supported languages: en\n",
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - PlPeselRecognizer supported languages: pl, registry supported languages: en\n"
          ]
        }
      ],
      "source": [
        "from presidio_analyzer import AnalyzerEngine\n",
        "from presidio_anonymizer import AnonymizerEngine\n",
        "\n",
        "analyzer = AnalyzerEngine()\n",
        "anonymizer = AnonymizerEngine()\n",
        "\"\"\"\n",
        "The below function will take a block of text, process it using presidio\n",
        "and return a block of text with the PII data redicated.\n",
        "PII data to be redicated:\n",
        "- Phone Numbers\n",
        "- Names\n",
        "- Addresses\n",
        "- Email addresses\n",
        "- US Social Security Numbers\n",
        "\"\"\"\n",
        "def anonymize_my_text(text):\n",
        "  results = analyzer.analyze(text=text,\n",
        "                           entities=[\"PHONE_NUMBER\", \"PERSON\", \"LOCATION\", \"EMAIL_ADDRESS\",\"US_SSN\"],\n",
        "                           language='en')\n",
        "  anonymized_text = anonymizer.anonymize(text=text,analyzer_results=results)\n",
        "  return anonymized_text.text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ehhx3gK_teZQ"
      },
      "source": [
        "**Now we start building our tracing using Weave's Traces:**\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1s8ObFo3ngfI"
      },
      "source": [
        "Let's load our initial PII data. For demonstration purposes, we'll use a dataset containing 10 text blocks. A larger dataset with 1000 entries is available at [link].\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "1hyDUVTZsOUb"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "with open('10_pii_data.json') as f:\n",
        "    pii_data = json.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OsBADqp2u7-S"
      },
      "outputs": [],
      "source": [
        "# @title Make sure to set up set up your API keys correctly\n",
        "from set_env import set_env\n",
        "_ = set_env(\"ANTHROPIC_API_KEY\")\n",
        "_ = set_env(\"WANDB_API_KEY\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D7D0ZBtiAvD8"
      },
      "source": [
        "In this example, we'll create a [Weave Model](https://wandb.github.io/weave/guides/core-types/models) which is a combination of data (which can include configuration, trained model weights, or other information) and code that defines how the model operates.\n",
        "In this model, we will include our predict function where the Anthropic API will be called.\n",
        "\n",
        "Once you run this code you will receive a link to the Weave project page"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sTGbemoMtcO8"
      },
      "outputs": [],
      "source": [
        "import weave\n",
        "import asyncio\n",
        "from anthropic import AsyncAnthropic\n",
        "\n",
        "# Weave model / predict function\n",
        "class sentiment_analysis_model(weave.Model):\n",
        "    model_name: str\n",
        "    system_prompt: str\n",
        "    temperature: int\n",
        "\n",
        "    @weave.op()\n",
        "    async def predict(self, text_block: str) -> dict:\n",
        "        client =AsyncAnthropic()\n",
        "\n",
        "        response = await client.messages.create(\n",
        "            max_tokens=1024,\n",
        "            model=self.model_name,\n",
        "            system=self.system_prompt,\n",
        "            messages=[\n",
        "                {   \"role\": \"user\",\n",
        "                    \"content\":[\n",
        "                        {\n",
        "                            \"type\": \"text\",\n",
        "                            \"text\": text_block\n",
        "                        }\n",
        "                        ]\n",
        "                 }\n",
        "            ]\n",
        "        )\n",
        "        result = response.content[0].text\n",
        "        if result is None:\n",
        "            raise ValueError(\"No response from model\")\n",
        "        parsed = json.loads(result)\n",
        "        return parsed\n",
        "\n",
        "\n",
        "weave.init('sentiment_analysis-example')\n",
        "# create our LLM model with a system prompt\n",
        "model = sentiment_analysis_model(name=\"claude-3-sonnet\",\n",
        "                      model_name=\"claude-3-5-sonnet-20240620\",\n",
        "                      system_prompt=\"You are a Sentiment Analysis classifier. You will be classifying text based on their sentiment. Your input will be a block of text. You will answer with one the following rating option[\\\"positive\\\", \\\"negative\\\", \\\"neutral\\\"]. Your answer should be one word in json format: {classification}\",\n",
        "                      temperature=0\n",
        "                      )\n",
        "# for every block of text, anonymized first and then predict\n",
        "for entry in pii_data:\n",
        "  anonymized_entry = anonymize_my_text(entry[\"text\"])\n",
        "  (await model.predict(anonymized_entry))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7omtvsdpMuel"
      },
      "source": [
        "# Method 1B: Replace PII data with fake data\n",
        "\n",
        "Instead of redacting text, we can anonymize it by swapping PII (like names and phone numbers) with fake data generated using the [Faker](https://faker.readthedocs.io/en/master/) Python library. For example:\n",
        "\n",
        "\n",
        "```\n",
        "\"My name is Raphael and I like to fish. My phone number is 212-555-5555\"\n",
        "```\n",
        "Will be:\n",
        "\n",
        "\n",
        "```\n",
        "\"My name is Katherine Dixon and I like to fish. My phone number is 667.431.7379\"\n",
        "\n",
        "```\n",
        "\n",
        "To effectively utilize Presidio, we must supply references to our custom operators. These operators will direct Presidio to the functions responsible for swapping PII with fake data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3XJa7u5T_WYd"
      },
      "outputs": [],
      "source": [
        "from presidio_anonymizer import AnonymizerEngine\n",
        "from presidio_anonymizer.entities import OperatorConfig, EngineResult, RecognizerResult\n",
        "from faker import Faker\n",
        "\n",
        "\n",
        "fake = Faker()\n",
        "\n",
        "# Create faker functions (note that it has to receive a value)\n",
        "def fake_name(x):\n",
        "    return fake.name()\n",
        "\n",
        "def fake_number(x):\n",
        "    return fake.phone_number()\n",
        "\n",
        "\n",
        "# Create custom operator for the PERSON and PHONE_NUMBER\" entities\n",
        "operators = {\n",
        "    \"PERSON\": OperatorConfig(\"custom\", {\"lambda\": fake_name}),\n",
        "    \"PHONE_NUMBER\": OperatorConfig(\"custom\", {\"lambda\": fake_number}),\n",
        "             }\n",
        "\n",
        "\n",
        "text_to_anonymize = \"My name is Raphael and I like to fish. My phone number is 212-555-5555\"\n",
        "\n",
        "# Analyzer output\n",
        "analyzer_results = analyzer.analyze(text=text_to_anonymize,\n",
        "                           entities=[\"PHONE_NUMBER\", \"PERSON\"],\n",
        "                           language='en')\n",
        "\n",
        "\n",
        "anonymizer = AnonymizerEngine()\n",
        "\n",
        "# do not forget to pass the operators from above to the anonymizer\n",
        "anonymized_results = anonymizer.anonymize(\n",
        "    text=text_to_anonymize, analyzer_results=analyzer_results, operators=operators\n",
        ")\n",
        "\n",
        "print(anonymized_results.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R4HJcskpSYdL"
      },
      "source": [
        "Let's consolidate our code into a single class and expand the list of entities to include the additional ones we identified earlier."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "yIaharNAWGh5"
      },
      "outputs": [],
      "source": [
        "from presidio_anonymizer import AnonymizerEngine\n",
        "from presidio_anonymizer.entities import OperatorConfig, EngineResult, RecognizerResult\n",
        "from faker import Faker\n",
        "import weave\n",
        "import asyncio\n",
        "from anthropic import AsyncAnthropic\n",
        "\n",
        "# Let's build a custom class for generating fake data that will extend Faker\n",
        "class my_faker(Faker):\n",
        "\n",
        "  # Create faker functions (note that it has to receive a value)\n",
        "  def fake_address(x):\n",
        "    return fake.address()\n",
        "\n",
        "  def fake_ssn(x):\n",
        "    return fake.ssn()\n",
        "\n",
        "  def fake_name(x):\n",
        "    return fake.name()\n",
        "\n",
        "  def fake_number(x):\n",
        "    return fake.phone_number()\n",
        "\n",
        "  def fake_email(x):\n",
        "    return fake.email()\n",
        "\n",
        "  # Create custom operators for the entities\n",
        "  operators = {\n",
        "    \"PERSON\": OperatorConfig(\"custom\", {\"lambda\": fake_name}),\n",
        "    \"PHONE_NUMBER\": OperatorConfig(\"custom\", {\"lambda\": fake_number}),\n",
        "    \"EMAIL_ADDRESS\": OperatorConfig(\"custom\", {\"lambda\": fake_email}),\n",
        "    \"LOCATION\": OperatorConfig(\"custom\", {\"lambda\": fake_address}),\n",
        "    \"US_SSN\":OperatorConfig(\"custom\", {\"lambda\": fake_ssn})\n",
        "             }\n",
        "\n",
        "  def anonymize_my_text(self, text):\n",
        "    anonymizer = AnonymizerEngine()\n",
        "    analyzer_results = analyzer.analyze(text=text,\n",
        "                           entities=[\"PHONE_NUMBER\", \"PERSON\", \"LOCATION\", \"EMAIL_ADDRESS\", \"US_SSN\"],\n",
        "                           language='en')\n",
        "    anonymized_results = anonymizer.anonymize(text=text,\n",
        "                            analyzer_results=analyzer_results, operators=self.operators)\n",
        "    return anonymized_results.text\n",
        "\n",
        "\n",
        "# Weave model / predict function\n",
        "class sentiment_analysis_model(weave.Model):\n",
        "    model_name: str\n",
        "    system_prompt: str\n",
        "    temperature: int\n",
        "\n",
        "    @weave.op()\n",
        "    async def predict(self, text_block: str) -> dict:\n",
        "        client = AsyncAnthropic()\n",
        "\n",
        "        response = await client.messages.create(\n",
        "            max_tokens=1024,\n",
        "            model=self.model_name,\n",
        "            system=self.system_prompt,\n",
        "            messages=[\n",
        "                {   \"role\": \"user\",\n",
        "                    \"content\":[\n",
        "                        {\n",
        "                            \"type\": \"text\",\n",
        "                            \"text\": text_block\n",
        "                        }\n",
        "                        ]\n",
        "                 }\n",
        "            ]\n",
        "        )\n",
        "        result = response.content[0].text\n",
        "        if result is None:\n",
        "            raise ValueError(\"No response from model\")\n",
        "        parsed = json.loads(result)\n",
        "        return parsed\n",
        "\n",
        "\n",
        "### Start our fun work here ###\n",
        "weave.init('sentiment_analysis-example')\n",
        "# create our LLM model with the system prompt\n",
        "model = sentiment_analysis_model(name=\"claude-3-sonnet\",\n",
        "                      model_name=\"claude-3-5-sonnet-20240620\",\n",
        "                      system_prompt=\"You are a Sentiment Analysis classifier. You will be classifying text based on their sentiment. Your input will be a block of text. You will answer with one the following rating option[\\\"positive\\\", \\\"negative\\\", \\\"neutral\\\"]. Your answer should one word in json format dict where the key is classification.\",\n",
        "                      temperature=0\n",
        "                      )\n",
        "faker = my_faker()\n",
        "for entry in pii_data:\n",
        "  anonymized_entry = faker.anonymize_my_text(entry[\"text\"])\n",
        "  (await model.predict(anonymized_entry))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Optional Step*: For data traceability, add a hashing function after the anonymization process. This hash can be used to link the anonymized data back to its original form.\n",
        "\n",
        "***Happy tracing!***"
      ],
      "metadata": {
        "id": "xHltGLxARdKC"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "XiRkYiiIj2KX"
      ],
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}